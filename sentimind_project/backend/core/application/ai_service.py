"""
Motor de MinerÃ­a de Texto basado en Transformers.
Usa el modelo XLM-RoBERTa cargado localmente.
"""
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import os


class MiningEngine:
    """
    Motor de MinerÃ­a de Texto basado en Transformers.
    PatrÃ³n Singleton para cargar el modelo en memoria una sola vez.
    
    CaracterÃ­sticas:
    - ClasificaciÃ³n Zero-Shot multilingÃ¼e (optimizado para espaÃ±ol)
    - Soporte multi-label (un post puede tener mÃºltiples emociones)
    - Umbral configurable para detectar emociones secundarias
    """
    
    # Lista expandida de categorÃ­as para la red social (25 categorÃ­as)
    TAXONOMY = [
        # Emociones bÃ¡sicas
        "AlegrÃ­a", "Tristeza", "Enojo", "Miedo", "Sorpresa", "Asco",
        # Emociones sociales
        "Amor", "Odio", "VergÃ¼enza", "Orgullo", "Envidia", "Celos",
        # Tipos de contenido
        "Humor", "InspiraciÃ³n", "ConfesiÃ³n", "Queja", "Consejo",
        "Pregunta", "ReflexiÃ³n", "Nostalgia", "Ansiedad", "FrustraciÃ³n",
        # Contenido especial
        "Sarcasmo", "PolÃ©mica", "Terror"
    ]
    
    # Mapeo de etiquetas a hypothesis templates en espaÃ±ol para mejor precisiÃ³n
    HYPOTHESIS_TEMPLATE = "Este texto expresa {}"
    
    # Umbral mÃ­nimo de confianza (porcentaje del score mÃ¡ximo)
    # Una emociÃ³n secundaria debe tener al menos 90% del score de la primaria
    RELATIVE_THRESHOLD = 0.90
    
    # MÃ¡ximo de emociones a retornar
    MAX_EMOTIONS = 3

    _classifier = None

    @classmethod
    def get_classifier(cls):
        if cls._classifier is None:
            print("ðŸ§  Cargando modelo neuronal multilingÃ¼e XLM-RoBERTa... (esto pasa solo una vez)")
            
            # Modelo multilingÃ¼e potente
            model_name = "joeddav/xlm-roberta-large-xnli"
            
            try:
                # Cargar tokenizer con sentencepiece (use_fast=False)
                print(f"ðŸ“¦ Cargando tokenizer para {model_name}...")
                tokenizer = AutoTokenizer.from_pretrained(
                    model_name, 
                    use_fast=False,
                    local_files_only=False
                )
                
                print(f"ðŸ“¦ Cargando modelo {model_name}...")
                cls._classifier = pipeline(
                    "zero-shot-classification",
                    model=model_name,
                    tokenizer=tokenizer,
                    device=-1  # CPU
                )
                print(f"âœ… Modelo {model_name} cargado exitosamente!")
                
            except Exception as e:
                print(f"âš ï¸ Error cargando XLM-RoBERTa: {e}")
                print("ðŸ”„ Intentando con modelo BART (fallback)...")
                
                try:
                    model_name = "facebook/bart-large-mnli"
                    cls._classifier = pipeline(
                        "zero-shot-classification",
                        model=model_name,
                        device=-1
                    )
                    print(f"âœ… Modelo fallback {model_name} cargado!")
                except Exception as e2:
                    print(f"âŒ Error tambiÃ©n con fallback: {e2}")
                    raise RuntimeError(f"No se pudo cargar ningÃºn modelo: {e}, {e2}")
                
        return cls._classifier

    @classmethod
    def analyze(cls, text: str) -> dict:
        """
        Analiza un texto y retorna mÃºltiples emociones detectadas.
        
        Returns:
            dict: {
                "categories": [{"name": "AlegrÃ­a", "confidence": 0.85}, ...],
                "primary_category": "AlegrÃ­a",
                "primary_confidence": 0.85,
                "all_scores": {...}
            }
        """
        print(f"ðŸ§  Analizando: '{text[:50]}...'")
        
        classifier = cls.get_classifier()
        
        # Inferencia con multi_label=True para detectar mÃºltiples emociones
        result = classifier(
            text, 
            cls.TAXONOMY, 
            hypothesis_template=cls.HYPOTHESIS_TEMPLATE,
            multi_label=True
        )
        
        # Crear diccionario de scores
        all_scores = dict(zip(result['labels'], result['scores']))
        
        # Obtener el score mÃ¡ximo para calcular umbrales relativos
        max_score = result['scores'][0]
        threshold = max_score * cls.RELATIVE_THRESHOLD
        
        # Filtrar emociones que superen el umbral relativo
        detected_categories = []
        for label, score in zip(result['labels'], result['scores']):
            if score >= threshold and len(detected_categories) < cls.MAX_EMOTIONS:
                detected_categories.append({
                    "name": label,
                    "confidence": round(score, 2)
                })
        
        # Si ninguna supera el umbral, tomar la mÃ¡s alta
        if not detected_categories:
            detected_categories = [{
                "name": result['labels'][0],
                "confidence": round(result['scores'][0], 2)
            }]
        
        print(f"âœ… Resultado: {detected_categories[0]['name']} ({detected_categories[0]['confidence']})")
        
        return {
            "categories": detected_categories,
            "primary_category": result['labels'][0],
            "primary_confidence": round(result['scores'][0], 2),
            "all_scores": {k: round(v, 2) for k, v in all_scores.items()},
            "method": "xlm-roberta-local"
        }
