{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e559f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   texto  sentimiento\n",
      "0  Â¡Me encanta este producto, es genial!            1\n",
      "1        El servicio fue pÃ©simo y lento.            0\n",
      "2        LlegÃ³ a tiempo y funciona bien.            1\n",
      "3             No me gustÃ³, mala calidad.            0\n",
      "4         Estoy muy feliz con la compra.            1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creamos un dataset pequeÃ±o de ejemplo\n",
    "data = [\n",
    "    (\"Â¡Me encanta este producto, es genial!\", 1),  # Positivo\n",
    "    (\"El servicio fue pÃ©simo y lento.\", 0),        # Negativo\n",
    "    (\"LlegÃ³ a tiempo y funciona bien.\", 1),        # Positivo\n",
    "    (\"No me gustÃ³, mala calidad.\", 0),             # Negativo\n",
    "    (\"Estoy muy feliz con la compra.\", 1)          # Positivo\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['texto', 'sentimiento'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2868ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Â¡Me encanta este producto, es genial!\n",
      "Procesado: ['encanta', 'producto', 'genial']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "texto_original = \"Â¡Me encanta este producto, es genial!\"\n",
    "\n",
    "# 1. Limpieza (Quitar signos y minÃºsculas)\n",
    "texto_limpio = re.sub(r'[^\\w\\s]', '', texto_original).lower()\n",
    "\n",
    "# 2. TokenizaciÃ³n (Dividir en palabras)\n",
    "tokens = texto_limpio.split()\n",
    "\n",
    "# 3. Stopwords (Quitar palabras vacÃ­as manualmente para el ejemplo)\n",
    "stopwords = {'me', 'este', 'es', 'el', 'la', 'y'}\n",
    "tokens_filtrados = [w for w in tokens if w not in stopwords]\n",
    "\n",
    "print(f\"Original: {texto_original}\")\n",
    "print(f\"Procesado: {tokens_filtrados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85f42c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: ['bien' 'calidad' 'compra' 'con' 'el' 'encanta' 'es' 'este' 'estoy'\n",
      " 'feliz' 'fue' 'funciona' 'genial' 'gustÃ³' 'la' 'lento' 'llegÃ³' 'mala'\n",
      " 'me' 'muy' 'no' 'producto' 'pÃ©simo' 'servicio' 'tiempo']\n",
      "Vector Frase 1: [[0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "# Transformamos nuestros textos a nÃºmeros\n",
    "matriz_bow = vectorizer.fit_transform(df['texto'])\n",
    "\n",
    "# Mostramos el vocabulario aprendido y el vector de la primera frase\n",
    "print(\"Vocabulario:\", vectorizer.get_feature_names_out())\n",
    "print(\"Vector Frase 1:\", matriz_bow[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebab5dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('meets', 0.8841923475265503), ('prince', 0.832163393497467), ('queen', 0.8257461190223694), ('â€™s', 0.8174097537994385), ('crow', 0.813499391078949), ('hunter', 0.8131037950515747), ('father', 0.8115833401679993), ('soldier', 0.81113600730896), ('mercy', 0.8082392811775208), ('hero', 0.8082262277603149)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Descargamos un modelo pre-entrenado (ej. Twitter)\n",
    "# Esto convierte palabras en coordenadas matemÃ¡ticas\n",
    "modelo_w2v = api.load(\"glove-twitter-25\")\n",
    "\n",
    "# Verificamos si la mÃ¡quina entiende la relaciÃ³n\n",
    "vector_rey = modelo_w2v['king']\n",
    "vector_reina = modelo_w2v['queen']\n",
    "\n",
    "# La magia: Rey - Hombre + Mujer = Â¿Reina?\n",
    "resultado = modelo_w2v.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(resultado) # DeberÃ­a decir 'queen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6009b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¡Modelo entrenado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Vectorizamos con TF-IDF (MÃ¡s avanzado que Bag of Words)\n",
    "tfidf = TfidfVectorizer(stop_words=['el', 'la', 'y', 'de'])\n",
    "X = tfidf.fit_transform(df['texto'])\n",
    "y = df['sentimiento']\n",
    "\n",
    "# 2. Entrenamos el modelo (RegresiÃ³n LogÃ­stica)\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X, y)\n",
    "\n",
    "print(\"Â¡Modelo entrenado exitosamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f486c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado: ðŸ˜¡ Negativo\n",
      "Confianza: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Nuevo comentario que llega al sistema\n",
    "nuevo_comentario = [\"El servicio fue pÃ©simo y lento\"]\n",
    "\n",
    "# 1. Convertimos el texto a nÃºmeros (usando el MISMO transformador)\n",
    "nuevo_vector = tfidf.transform(nuevo_comentario)\n",
    "\n",
    "# 2. El modelo predice\n",
    "prediccion = modelo.predict(nuevo_vector)\n",
    "probabilidad = modelo.predict_proba(nuevo_vector)\n",
    "\n",
    "if prediccion[0] == 1:\n",
    "    print(\"Resultado: ðŸ˜€ Positivo\")\n",
    "else:\n",
    "    print(\"Resultado: ðŸ˜¡ Negativo\")\n",
    "    \n",
    "print(f\"Confianza: {probabilidad.max():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
